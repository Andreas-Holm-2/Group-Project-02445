{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import cochrans_q\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "from mlxtend.evaluate import mcnemar\n",
    "from results import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cochran's Q-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common\n",
      "Q: 84.10526315789474\n",
      "p-value: 2.348409661759755e-17\n",
      "\n",
      "justice\n",
      "Q: 50.20289855072464\n",
      "p-value: 3.275244409497549e-10\n",
      "\n",
      "virtue\n",
      "Q: 13.26530612244898\n",
      "p-value: 0.010049649085819049\n",
      "\n",
      "dentology\n",
      "Q: 39.54140127388535\n",
      "p-value: 5.3844947321518655e-08\n",
      "\n",
      "all_categories\n",
      "Q: 124.43392504930966\n",
      "p-value: 6.030455535286086e-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_values = [\"common\", \"justice\", \"virtue\", \"dentology\", \"all_categories\"]\n",
    "\n",
    "for value in list_of_values:\n",
    "    y_model_1 = globals()[\"gpt35_\" + value]\n",
    "\n",
    "    y_model_2 = globals()[\"gpt4_\" + value]\n",
    "\n",
    "    y_model_3 = globals()[\"llama70_\" + value]\n",
    "\n",
    "    y_model_4 = globals()[\"Gemini_\" + value]\n",
    "\n",
    "    y_model_5 = globals()[\"Claude3_\" + value]\n",
    "\n",
    "    y_true = globals()[\"y_\" + value]\n",
    "\n",
    "    q, p_value = cochrans_q(y_true, \n",
    "                        y_model_1, \n",
    "                        y_model_2, \n",
    "                        y_model_3,\n",
    "                        y_model_4,\n",
    "                        y_model_5\n",
    "                        )\n",
    "    print (value)\n",
    "    print('Q:', q)\n",
    "    print('p-value:', p_value)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mcnemar test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- common -----------------\n",
      "GPT-3.5 GPT-4o 1.862645149230957e-09 ------ True\n",
      "GPT-3.5 Llama 0.6900379657745361 ------ False\n",
      "GPT-3.5 Gemini 2.384185791015625e-07 ------ True\n",
      "GPT-3.5 Claude3 2.9802322387695312e-08 ------ True\n",
      "GPT-4o Llama 2.0954757928848267e-09 ------ True\n",
      "GPT-4o Gemini 0.015625 ------ False\n",
      "GPT-4o Claude3 0.21875 ------ False\n",
      "Llama Gemini 6.16488978266716e-06 ------ True\n",
      "Llama Claude3 4.176981747150421e-07 ------ True\n",
      "Gemini Claude3 0.453125 ------ False\n",
      "----------------- justice -----------------\n",
      "GPT-3.5 GPT-4o 1.5236437320709229e-05 ------ True\n",
      "GPT-3.5 Llama 0.39152830513194203 ------ False\n",
      "GPT-3.5 Gemini 0.22948101302608848 ------ False\n",
      "GPT-3.5 Claude3 0.00017999112606048584 ------ True\n",
      "GPT-4o Llama 7.62939453125e-05 ------ True\n",
      "GPT-4o Gemini 1.233129296451807e-07 ------ True\n",
      "GPT-4o Claude3 0.5078125 ------ False\n",
      "Llama Gemini 0.028816719655878845 ------ False\n",
      "Llama Claude3 0.000518798828125 ------ True\n",
      "Gemini Claude3 7.660128176212311e-07 ------ True\n",
      "----------------- virtue -----------------\n",
      "GPT-3.5 GPT-4o 0.08014331245794892 ------ False\n",
      "GPT-3.5 Llama 0.029449373483657837 ------ False\n",
      "GPT-3.5 Gemini 0.01690053939819336 ------ False\n",
      "GPT-3.5 Claude3 0.012540951371192932 ------ False\n",
      "GPT-4o Llama 0.75390625 ------ False\n",
      "GPT-4o Gemini 1.0 ------ False\n",
      "GPT-4o Claude3 0.6072387695312499 ------ False\n",
      "Llama Gemini 1.0000000000000002 ------ False\n",
      "Llama Claude3 1.0 ------ False\n",
      "Gemini Claude3 0.7744140625 ------ False\n",
      "----------------- dentology -----------------\n",
      "GPT-3.5 GPT-4o 5.398760549724102e-09 ------ True\n",
      "GPT-3.5 Llama 0.054076031858869555 ------ False\n",
      "GPT-3.5 Gemini 0.024306510109454393 ------ False\n",
      "GPT-3.5 Claude3 5.9476122260093696e-05 ------ True\n",
      "GPT-4o Llama 0.0005350527353584766 ------ True\n",
      "GPT-4o Gemini 8.797645568847656e-05 ------ True\n",
      "GPT-4o Claude3 0.01690053939819336 ------ False\n",
      "Llama Gemini 1.139949934091419 ------ False\n",
      "Llama Claude3 0.21532714972272515 ------ False\n",
      "Gemini Claude3 0.13380050659179688 ------ False\n",
      "----------------- all_categories -----------------\n",
      "GPT-3.5 GPT-4o 2.0703656210246182e-19 ------ True\n",
      "GPT-3.5 Llama 0.012604512869782385 ------ False\n",
      "GPT-3.5 Gemini 0.00014401960112955247 ------ True\n",
      "GPT-3.5 Claude3 7.121860330286232e-16 ------ True\n",
      "GPT-4o Llama 7.242756461984744e-13 ------ True\n",
      "GPT-4o Gemini 7.237363065075456e-10 ------ True\n",
      "GPT-4o Claude3 0.03648340000835981 ------ False\n",
      "Llama Gemini 0.35527968165224766 ------ False\n",
      "Llama Claude3 6.65366562409261e-08 ------ True\n",
      "Gemini Claude3 2.1823279653758543e-06 ------ True\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import scipy.stats as st\n",
    "\n",
    "def mcnemar(y_true, yhatA, yhatB, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform McNemar's test to compare the accuracy of two classifiers.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: array-like, true labels\n",
    "    - yhatA: array-like, predicted labels by classifier A\n",
    "    - yhatB: array-like, predicted labels by classifier B\n",
    "    - alpha: float, significance level (default: 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - thetahat: float, estimated difference in accuracy between classifiers A and B\n",
    "    - CI: tuple, confidence interval of the estimated difference in accuracy\n",
    "    - p: float, p-value for the two-sided test of whether classifiers A and B have the same accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    nn = np.zeros((2, 2))\n",
    "    c1 = yhatA - y_true == 0\n",
    "    c2 = yhatB - y_true == 0\n",
    "\n",
    "    nn[0, 0] = sum(c1 & c2)\n",
    "    nn[0, 1] = sum(c1 & ~c2)\n",
    "    nn[1, 0] = sum(~c1 & c2)\n",
    "    nn[1, 1] = sum(~c1 & ~c2)\n",
    "\n",
    "    n = sum(nn.flat)\n",
    "    n12 = nn[0, 1]\n",
    "    n21 = nn[1, 0]\n",
    "\n",
    "    thetahat = (n12 - n21) / n\n",
    "    Etheta = thetahat\n",
    "\n",
    "    Q = (\n",
    "        n**2\n",
    "        * (n + 1)\n",
    "        * (Etheta + 1)\n",
    "        * (1 - Etheta)\n",
    "        / ((n * (n12 + n21) - (n12 - n21) ** 2))\n",
    "    )\n",
    "\n",
    "    p = (Etheta + 1) * 0.5 * (Q - 1)\n",
    "    q = (1 - Etheta) * 0.5 * (Q - 1)\n",
    "\n",
    "    CI = tuple(lm * 2 - 1 for lm in scipy.stats.beta.interval(1 - alpha, a=p, b=q))\n",
    "\n",
    "    p = 2 * scipy.stats.binom.cdf(min([n12, n21]), n=n12 + n21, p=0.5)\n",
    "\n",
    "    return nn, thetahat, CI, p\n",
    "\n",
    "list_of_values = [\"common\", \"justice\", \"virtue\", \"dentology\", \"all_categories\"]\n",
    "category = ''\n",
    "\n",
    "count = 0\n",
    "\n",
    "for value in list_of_values:\n",
    "    y_model_1 = globals()[\"gpt35_\" + value]\n",
    "\n",
    "    y_model_2 = globals()[\"gpt4_\" + value]\n",
    "\n",
    "    y_model_3 = globals()[\"llama70_\" + value]\n",
    "\n",
    "    y_model_4 = globals()[\"Gemini_\" + value]\n",
    "\n",
    "    y_model_5 = globals()[\"Claude3_\" + value]\n",
    "\n",
    "    y_true = globals()[\"y_\" + value]\n",
    "\n",
    "    models = [y_model_1, y_model_2, y_model_3, y_model_4, y_model_5]\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        for j in range(i + 1, len(models)):\n",
    "            model1 = models[i]\n",
    "            model2 = models[j]\n",
    "\n",
    "            nn, thetahat, CI, p = mcnemar(y_true, model1, model2)\n",
    "            \n",
    "            model1name = ''\n",
    "            model2name = ''\n",
    "            if(i == 0):\n",
    "                model1name = \"GPT-3.5\"\n",
    "            elif(i==1):\n",
    "                model1name = \"GPT-4o\"\n",
    "            elif(i==2):\n",
    "                model1name = \"Llama\"\n",
    "            elif(i==3):\n",
    "                model1name = \"Gemini\"\n",
    "            elif(i==4):\n",
    "                model1name = \"Claude3\"\n",
    "            \n",
    "            if(j == 0):\n",
    "                model2name = \"GPT-3.5\"\n",
    "            elif(j==1):\n",
    "                model2name = \"GPT-4o\"\n",
    "            elif(j==2):\n",
    "                model2name = \"Llama\"\n",
    "            elif(j==3):\n",
    "                model2name = \"Gemini\"\n",
    "            elif(j==4):\n",
    "                model2name = \"Claude3\"\n",
    "            \n",
    "            if(category != value):\n",
    "                category = value\n",
    "                print('----------------- ' + category + ' -----------------')\n",
    "            \n",
    "            alpha = 0.05\n",
    "            n = 40\n",
    "            \n",
    "            significance = p < alpha/n\n",
    "\n",
    "            if(significance):\n",
    "                count += 1\n",
    "\n",
    "            print(model1name,model2name, p, '------',significance)\n",
    "\n",
    "print(count)\n",
    "\n",
    "# 95% sandsynlighed for at der er signifkant forskel.\n",
    "# 5% af tiden har vi taget fejl, vi siger de er forskellige men de er ens.\n",
    "# \n",
    "# 1 gang: sandsynligheden for fejlen er 5%\n",
    "# 5 gang: sandsynligheden for fejlen er 25% (gæt)\n",
    "# 40 gange: sandsynligheden er meget stor\n",
    "# derfor gør vi alpha mindfre \n",
    "            \n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
